# ScratchGPT
Bigram transformer model from scratch (Shakespearean corpus)

Essentially, transformers are encoder-decoder models
That is, they take an input (user prompt) --> encode it (tokenization) --> let the tokens talk between each other (self and cross attention) --> decode it (generate next most probable set of words).
This is how chatgpt works: it encodes the user prompt, makes sense of what the encoded data is, tries to find a relation between each token (each token has a weight-->how much probable it is to appear after the previous token), and finally generates a sequence of tokens in a probabilistic manner.

The Shakespeare model is technically half of GPT... its trained on a corpus of Shakespearean text and asked to generate random text based on the weights and biases it has learned during model compile.
This phase is called pretraining ---> the first half of model training.

The second half is finetuning ---> changing the parameters (like temperature, num_tokens, categorization) to generate better tokens to a user prompt.
This is why chatgpt responds more like a human than a chatbot

The data used for training the model is the total collection of all Shakespearean works available in a 1MB file [input.txt](input.txt).
[train.ipynb](train.ipynb) is just a breakdown of the transformer architecture I wrote for future editing. [bigram.py](bigram.py) provides a more concise and condensed format of training the model. It uses over 10 million parameters in training, depending on how you modulate your usage of hyperparameters in the code. [MODEL.py](MODEL.py) is probably what you are looking for, as it loads the pre-trained model straight out of the directory and generates text upon execution.

**4000 character text generated by ScratchGPT on RTX 3050:**

Lineless,
How craves bastardy or two and the compest-seet.
Ah, what enrolled gate Rutland's death!
Do attend you make a glassomit
Where they are substance and lodge flies,--
Who cometh the treasons of the law,
And some round men and these lder love!

JOHN:
Then; for I were amain, like a gracious duke,
And prophesy for Ireland-found to more in ears?
Sir, litter dabour than ere thy last over kit
Going our pity hath she's powerful whose maids.
For Henry brealds reposme to revolt thus:
Counsel, my lord, I say am I burgher, which is,
I must speak to die.

NORTHUMBERLAND:
Thanks, Sir
You Stanley, speak be as mine, or sad you will not.

BUCKINGHAM:
Thws are you?

BUSHY:
Bothee, my lord.

HASTINGS:
Go, the Earl of Warwick's executioner?

BUCKINGHAM:
Not why?
From I hence, courager: there take her leave to leave me.
Sirrah, go provost, with froward Jushes;
And I, look me the recounty alord.
Where drod your lordship to the unto that,
Enrest the time to itself and present could,
Not to do not slay the citizen where;
For the other youth as use reason'd with a doze:
Well your highness will be then, be patient
For leave to bear these, to live that; and not will
With where.

First Citizen:
Ay, away, when I, them how to be a subject?

Second Citizen:
Amen.

Second Citizen:
Why, what's the wenchmen?

First Citizen:
Nay, we shall!

Citizen:
I beseech you, sir.

MENENIUS:
This business is as I heard as samed two.

Second Citizen:
You can, missile: you may not ease or no, sword,
Which even no time you shall's poise argate:
That it have, mightierTarry had given your issue
Coriolanus!

LEONTES:
What?

CORIOLANUS:
By my tribunes!
If my joining trippes be to him, plainly vine
Murder the admam's part. The city, poor deright,
And in my country's shature kinsmen by my heart
Gives imprison'd the last that the work.

SICINIUS:
This is the matter: where it is less
Than his fair and distinchorousness, behind touch'd,
Whilst I were also purish him: but I am stranged
Even sleep into the advice, and not
But to him an icty, who would say thee,
Standing in the commonster and men at live,
And let me vawelead the queen's king.
Come, come, come, morerat let's away.

Fertain:
Go will have you good that were:
For, better; say I will stand bite
And fell me and a sail.

Apothecary:
Look, he sets of you with his looking to his war.

Lord:
They have person'd a tediousure.

First Citizen:
What would you please, he do not do?

Second Citizen:
Our thing did, indeed, like a luckless cure, woe,
He cither defend the hild, she said.

Second Citizen:
Wherewar you have.

Second Citizen:
Unto marry?

Third Citizen:
And go you with the haughter.

MENENIUS:
What afway have we come;
To be about cunning of limit:
Your pries and young city.

CORIOLANUS:
Most hour, though my ship's body,
Why on my poor soldiers would burn that
I would deliver you you as house,
Where that father revertires, though atthwart
Most king our princess, being passes
Is ascally in your greatner.

MENENIUS:
Towards  silence?

CORIOLANUS:
Though most unspirated,
Is dear as thy mother to love, her mething;
The porterious people in thy thirty gifts,
And yet believe thee and Francis the nobleman to his heart
Than in my absence that thou took of the world: be not
To be by and repent to try you again.

LUCIO:

It does:
Sweet not. come, we so?

ISABELLA:
Where's has your tongue here?

ANGELO:
Who as my lord?

MISTRESS:
Propsheer?

ANGELO:
If an imputed-bawd or need?

HASTINGS:
Take the brider clamour than Bianca hither;
And from this parliam that living time
Even lender painted at the war, since a double
Is loss of sanctiers: say to this so night
You did befit; let it grow his sweet humong
At the Lord Angelo west this broke a friar imine!
Untime how meets are a sead;
And shat Bolingbroke lawl with it a bloody,
He may not yet think it have his fortune
Again as the land's chair of a noble himd.
Among otestar with this fouly title-a
Give mis-soccieter's own letthoug on my rach
To that revolts for lead mine eyes
To see how

**Notes:**

Switch device to 'cpu' if no CUDA device available.
If you are training from the boilerplate code, I suggest running it on Colab's T4 (or if you're brave, on the A100).
Playing with the block_size and batch_size should generate some interesting results.

Joi will require an encoder and decoder segment.
And she will have to be trained on a larger, more conversational corpus of information.
Au Revoir.
